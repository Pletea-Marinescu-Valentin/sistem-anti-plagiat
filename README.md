# Anti-Plagiarism Monitoring System

An advanced real-time monitoring system for preventing plagiarism during examinations, implemented in Python with PyQt5 and enhanced computer vision algorithms using MediaPipe and YOLOv8.

## üöÄ Features

### Core Monitoring Capabilities
- **Real-time Surveillance**: Continuously monitors candidate activity using webcam feed
- **Advanced Gaze Tracking**: Utilizes MediaPipe facial landmark detection with sophisticated eye-tracking algorithms for precise gaze direction detection
- **Prohibited Object Detection**: Identifies forbidden items such as mobile phones, smartwatches, and other electronic devices using YOLOv8 models
- **Video Recording**: Records video streams with violation annotations for later review
- **Live Violation Alerts**: Instant notifications when suspicious behavior is detected

### Enhanced Detection System
- **MediaPipe Face Mesh**: High-precision 468-point facial landmark detection for robust eye tracking
- **Multi-layered Pupil Detection**: Combines contour analysis with circularity validation for robust pupil identification
- **Head Pose Compensation**: Automatically adjusts for head rotation and tilt to maintain accuracy
- **Confidence-based Filtering**: Uses detection confidence scores to reduce false positives
- **Temporal Smoothing**: Implements advanced filtering for stable, noise-free tracking
- **User Calibration**: Personalizes detection thresholds for individual users

### Reporting and Analysis
- **Comprehensive Reports**: Generates detailed violation reports with timestamps, screenshots, and descriptions
- **Data Export**: Exports monitoring data in multiple formats (JSON, CSV, PDF)
- **Statistical Analysis**: Provides violation frequency and pattern analysis
- **Batch Image Processing**: Standalone utility for testing gaze detection on static images

## ‚ö° Quick Start

**For experienced users - minimum steps to run:**

```bash
# 1. Install system dependencies (Linux)
sudo apt update && sudo apt install cmake
sudo apt install -y libxcb-xinerama0 libxcb-cursor0 libxkbcommon-x11-0 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-randr0 libxcb-render-util0 libxcb-shape0

# 2. Create conda environment
conda env create -f environment.yml
conda activate anti-plagiat

# 3. Install additional packages
pip install ultralytics
pip uninstall opencv-python opencv-contrib-python opencv-python-headless
pip install opencv-python-headless==4.8.1.78

# 4. Run application
python gui_app.py
```

## üìã Requirements

### System Requirements
- **OS**: Linux (Ubuntu/Debian/Kali Linux recommended)
- **Python**: 3.11+
- **Memory**: Minimum 4GB RAM (8GB recommended)
- **Processor**: Multi-core processor recommended for real-time processing
- **Camera**: Webcam or compatible camera device
- **Storage**: 2GB free space for models and recordings

### Key Dependencies
- **conda/miniconda**: Environment management
- **CMake**: Required for dlib compilation
- **OpenCV**: Computer vision library
- **MediaPipe**: Face and landmark detection
- **PyQt5/PySide6**: GUI framework
- **YOLOv8 (ultralytics)**: Object detection
- **PyTorch**: Deep learning framework

## üõ†Ô∏è Installation

### Prerequisites

**System Requirements:**
- Linux (Ubuntu/Debian/Kali Linux recommended)
- Python 3.11+
- Conda/Miniconda
- CMake (for dlib compilation)

### 1. Install System Dependencies

**Install CMake and GUI libraries:**
```bash
# Install CMake (required for dlib)
sudo apt update
sudo apt install cmake

# Install Qt/GUI dependencies for Linux
sudo apt install -y libxcb-xinerama0 libxcb-cursor0 libxkbcommon-x11-0 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-randr0 libxcb-render-util0 libxcb-shape0
```

### 2. Clone the Repository
```bash
git clone <repository-url>
cd anti-plagiat
```

### 3. Create Conda Environment
```bash
# Create environment from environment.yml
conda env create -f environment.yml

# Activate the environment
conda activate anti-plagiat
```

### 4. Install Additional Dependencies
```bash
# Install ultralytics (YOLO)
pip install ultralytics

# Fix OpenCV for GUI compatibility
pip uninstall opencv-python opencv-contrib-python opencv-python-headless
pip install opencv-python-headless==4.8.1.78
```

### 5. Run the Application
```bash
python gui_app.py
```

### Alternative Installation (pip-only)
If you prefer not to use conda:
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install ultralytics

# Run application
python gui_app.py
```

## ‚öôÔ∏è Configuration

The system is configured through `config.json`:

```json
{
  "camera": {
    "source": 0,
    "mirror_image": true,
    "resolution": [640, 480],
    "fps": 30
  },
  "detection": {
    "gaze": {
      "left_limit": 0.65,
      "right_limit": 0.35,
      "down_limit": 0.55,
      "smoothing_factor": 0.3
    },
    "objects": {
      "phone_confidence": 0.55,
      "watch_confidence": 0.4,
      "nms_threshold": 0.4
    }
  },
  "recording": {
    "enabled": true,
    "save_path": "./recordings",
    "format": "mp4",
    "quality": "high"
  },
  "video": {
    "mirror_image": true,
    "show_landmarks": false,
    "alert_duration": 3.0
  }
}
```

### Key Configuration Parameters

#### Gaze Detection
- `left_limit` / `right_limit`: Horizontal gaze boundaries (0.0-1.0)
- `down_limit`: Vertical downward gaze threshold
- `smoothing_factor`: Temporal smoothing intensity (0.0-1.0)

#### Object Detection
- `phone_confidence`: Minimum confidence for phone detection
- `watch_confidence`: Minimum confidence for smartwatch detection
- `nms_threshold`: Non-maximum suppression threshold

#### Recording Settings
- `save_path`: Directory for recorded videos
- `format`: Video output format (mp4, avi)
- `quality`: Recording quality (low, medium, high)

## üéØ Usage

### Basic Operation

1. **Start Monitoring**
   ```bash
   python gui_app.py
   ```

2. **Generate Test Images** (Optional)
   ```bash
   python generate_test_images.py
   ```

3. **Begin Examination**
   - Click "Start Monitoring" to begin surveillance
   - System will automatically detect and log violations
   - Red alerts appear for detected violations

### Batch Image Processing

For testing gaze detection on static images:

```bash
# Place test images in input_images/ directory
python image_gaze_analyzer.py
# Check results in analyzed_images/ directory and logs/
```

### Advanced Features

#### Custom Violation Rules
```python
# Add custom violation detection
system.violation_monitor.add_custom_rule(
    name="extended_downward_gaze",
    condition=lambda data: data['v_ratio'] > 0.7,
    duration_threshold=3.0
)
```

#### Testing and Analysis Tools
- **Generate Test Images**: PyQt5-based tool for capturing calibrated gaze images
- **Image Gaze Analyzer**: Batch processing tool with detailed logging and analysis
- **Configuration Testing**: Tools to validate and optimize detection thresholds

## üèóÔ∏è Architecture

### Core Components

```
anti-plagiat/
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ gaze_tracking/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gaze_tracker.py      # MediaPipe-based gaze tracking engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ eye.py               # Eye region detection and analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pupil.py             # Enhanced pupil detection
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pupil_tracker.py     # Temporal tracking and filtering
‚îÇ   ‚îú‚îÄ‚îÄ face_detector.py         # Face detection integration
‚îÇ   ‚îú‚îÄ‚îÄ object_detector.py       # YOLOv8-based object detection
‚îÇ   ‚îú‚îÄ‚îÄ violation_monitor.py     # Violation detection logic
‚îÇ   ‚îú‚îÄ‚îÄ video_handler.py         # Video processing and recording
‚îÇ   ‚îî‚îÄ‚îÄ report_generator.py      # Report generation
‚îú‚îÄ‚îÄ gui_app.py                   # Main PyQt5 GUI application
‚îú‚îÄ‚îÄ main.py                      # Core system logic
‚îú‚îÄ‚îÄ generate_test_images.py      # PyQt5-based test image generator
‚îú‚îÄ‚îÄ image_gaze_analyzer.py       # Batch image analysis tool
‚îî‚îÄ‚îÄ config.json                  # Configuration file
```

### Algorithm Overview

#### Gaze Tracking Pipeline
1. **Face Detection**: MediaPipe Face Mesh detection with 468 landmarks
2. **Eye Region Isolation**: Extract left and right eye regions using specific landmarks
3. **Pupil Detection**: Multi-method pupil localization with geometric validation
4. **Gaze Calculation**: Compute horizontal and vertical ratios for direction determination
5. **Temporal Filtering**: Smoothing and noise reduction
6. **Violation Assessment**: Compare against configurable thresholds

#### Enhanced Object Detection
- **Dual YOLOv8 Models**: Separate specialized models for phones and smartwatches
- **Confidence Thresholding**: Different confidence levels for different object types
- **Dimension-based Classification**: Additional validation based on object dimensions
- **Temporal Consistency**: Multi-frame validation to reduce false positives

#### MediaPipe Integration
- **Face Mesh Detection**: 468 facial landmarks for precise eye tracking
- **Real-time Processing**: Optimized for live video streams
- **Robust Landmark Detection**: Works across various lighting conditions and poses
- **Silent Operation**: Suppressed output for clean user experience

## üîß Troubleshooting

### Common Issues

#### Camera Not Detected
```bash
# Check available cameras
python -c "import cv2; print([i for i in range(10) if cv2.VideoCapture(i).isOpened()])"
# Update camera source in config.json
```

#### Poor Gaze Detection Accuracy
1. Ensure good lighting conditions
2. Adjust detection thresholds in config.json
3. Check camera positioning (eye-level recommended)
4. Test with generate_test_images.py for calibration

#### High CPU Usage
1. Reduce camera resolution in config.json
2. Increase frame processing interval
3. Disable recording if not needed
4. Close other resource-intensive applications

#### Qt Platform Plugin Errors
```bash
# If using conda environment
export QT_QPA_PLATFORM_PLUGIN_PATH=""
export OPENCV_IO_ENABLE_OPENEXR=0
```

### Debug Mode
```bash
# Check logs in logs/ directory after running image analysis
python image_gaze_analyzer.py
# Logs saved to logs/gaze_analysis_YYYYMMDD_HHMMSS.log
```

## üß™ Testing

### Test Image Generation
```bash
# Generate calibrated test images
python generate_test_images.py
# Images saved to input_images/ directory
```

### Batch Analysis
```bash
# Analyze generated test images
python image_gaze_analyzer.py
# Results in analyzed_images/ and logs/
```

### Performance Testing
```bash
# Test camera functionality
python test_camera.py
```

## üìä Performance Metrics

### Typical Performance
- **Gaze Detection Accuracy**: 85-95% (with proper lighting and positioning)
- **Processing Speed**: 25-30 FPS (640x480 resolution)
- **False Positive Rate**: <5%
- **Object Detection Accuracy**: 88-94% (YOLOv8 models)

### Optimization Tips
- Use proper lighting setup
- Position camera at eye level
- Optimize camera resolution for use case
- Regular threshold adjustment based on environment
- Use headless OpenCV to avoid GUI conflicts

## üîß Troubleshooting

### Common Issues and Solutions

#### 1. CMake Error During Installation
**Error:** `CMake is not installed on your system!`
```bash
# Solution: Install CMake
sudo apt update
sudo apt install cmake
cmake --version  # Verify installation
```

#### 2. Qt Platform Plugin Error
**Error:** `Could not load the Qt platform plugin "xcb"`
```bash
# Solution: Install GUI dependencies
sudo apt install -y libxcb-xinerama0 libxcb-cursor0 libxkbcommon-x11-0 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-randr0 libxcb-render-util0 libxcb-shape0

# Alternative: Run headless
export QT_QPA_PLATFORM=offscreen
python gui_app.py
```

#### 3. ModuleNotFoundError: ultralytics
**Error:** `No module named 'ultralytics'`
```bash
# Solution: Install ultralytics
conda activate anti-plagiat
pip install ultralytics
```

#### 4. OpenCV GUI Conflicts
**Error:** GUI freezing or display issues
```bash
# Solution: Use headless OpenCV
pip uninstall opencv-python opencv-contrib-python opencv-python-headless
pip install opencv-python-headless==4.8.1.78
```

#### 5. Conda Environment Issues
**Error:** Environment creation fails
```bash
# Solution: Clean conda cache and retry
conda clean --all
conda env remove -n anti-plagiat  # If exists
conda env create -f environment.yml
```

#### 6. Camera Access Issues
**Error:** Camera not detected or permission denied
```bash
# Solution: Check camera permissions
sudo usermod -a -G video $USER
# Logout and login again

# Test camera
python -c "import cv2; cap = cv2.VideoCapture(0); print('Camera OK' if cap.isOpened() else 'Camera FAIL')"
```

#### 7. Low FPS Performance
**Issue:** Application running slowly
```bash
# Solutions:
# 1. Reduce camera resolution in config.json
# 2. Close other applications
# 3. Use GPU acceleration if available
# 4. Check CPU usage: htop
```

#### 8. Export Environment for Other Devices
```bash
# Export current environment
conda env export > environment.yml

# On new device:
conda env create -f environment.yml
conda activate anti-plagiat
```

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

### Development Guidelines
- Follow PEP 8 style guide
- Add docstrings for all functions
- Include unit tests for new features
- Update documentation as needed
- Test with both PyQt5 GUI and batch processing tools

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## üôè Acknowledgments

- **MediaPipe** library for facial landmark detection
- **OpenCV** for computer vision capabilities
- **PyQt5** for GUI framework
- **YOLOv8/Ultralytics** for object detection
- **NumPy** for numerical computations
- Research papers on gaze tracking and eye detection algorithms

## üìû Support

For support and questions:
- Create an issue on GitHub
- Check the troubleshooting section
- Review configuration documentation
- Check logs in logs/ directory for detailed analysis

## üîÑ Version History

- **v3.0.0**: Complete redesign with MediaPipe, YOLOv8, and enhanced PyQt5 tools
- **v2.0.0**: Enhanced gaze tracking with Kalman filtering and user calibration
- **v1.5.0**: Added object detection and improved GUI
- **v1.0.0**: Initial release with basic gaze tracking

---

**Note**: This system is designed for educational and examination monitoring purposes. Ensure compliance with local privacy laws and institutional policies before deployment.