# Anti-Plagiarism Monitoring System

An advanced real-time monitoring system for preventing plagiarism during examinations, implemented in Python with PyQt5 and enhanced computer vision algorithms using MediaPipe and YOLOv8.

## ğŸš€ Features

### Core Monitoring Capabilities
- **Real-time Surveillance**: Continuously monitors candidate activity using webcam feed
- **Advanced Gaze Tracking**: Utilizes MediaPipe facial landmark detection with sophisticated eye-tracking algorithms for precise gaze direction detection
- **Prohibited Object Detection**: Identifies forbidden items such as mobile phones, smartwatches, and other electronic devices using YOLOv8 models
- **Video Recording**: Records video streams with violation annotations for later review
- **Live Violation Alerts**: Instant notifications when suspicious behavior is detected

### Enhanced Detection System
- **MediaPipe Face Mesh**: High-precision 468-point facial landmark detection for robust eye tracking
- **Multi-layered Pupil Detection**: Combines contour analysis with circularity validation for robust pupil identification
- **Head Pose Compensation**: Automatically adjusts for head rotation and tilt to maintain accuracy
- **Confidence-based Filtering**: Uses detection confidence scores to reduce false positives
- **Temporal Smoothing**: Implements advanced filtering for stable, noise-free tracking
- **User Calibration**: Personalizes detection thresholds for individual users

### Reporting and Analysis
- **Comprehensive Reports**: Generates detailed violation reports with timestamps, screenshots, and descriptions
- **Data Export**: Exports monitoring data in multiple formats (JSON, CSV, PDF)
- **Statistical Analysis**: Provides violation frequency and pattern analysis
- **Batch Image Processing**: Standalone utility for testing gaze detection on static images

## ğŸ“‹ Requirements

### System Requirements
- Python 3.7+
- OpenCV 4.5+
- Qt5 libraries
- Webcam or compatible camera device
- Minimum 4GB RAM (8GB recommended)
- Multi-core processor recommended for real-time processing

### Python Dependencies
```bash
pip install -r requirements.txt
```

**Key Dependencies:**
- `opencv-python-headless>=4.5.0`
- `numpy>=1.21.0,<2.0.0`
- `PyQt5>=5.15.0`
- `mediapipe>=0.10.0`
- `ultralytics>=8.0.0`
- `torch>=2.0.0`

## ğŸ› ï¸ Installation

### 1. Clone the Repository
```bash
git clone <repository-url>
cd anti-plagiat
```

### 2. Create Virtual Environment (Recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Configure System
```bash
# Copy and edit configuration file
cp config.json.example config.json
# Edit config.json to match your requirements
```

### 5. Run the Application
```bash
python gui_app.py
```

## âš™ï¸ Configuration

The system is configured through `config.json`:

```json
{
  "camera": {
    "source": 0,
    "mirror_image": true,
    "resolution": [640, 480],
    "fps": 30
  },
  "detection": {
    "gaze": {
      "left_limit": 0.65,
      "right_limit": 0.35,
      "down_limit": 0.55,
      "smoothing_factor": 0.3
    },
    "objects": {
      "phone_confidence": 0.55,
      "watch_confidence": 0.4,
      "nms_threshold": 0.4
    }
  },
  "recording": {
    "enabled": true,
    "save_path": "./recordings",
    "format": "mp4",
    "quality": "high"
  },
  "video": {
    "mirror_image": true,
    "show_landmarks": false,
    "alert_duration": 3.0
  }
}
```

### Key Configuration Parameters

#### Gaze Detection
- `left_limit` / `right_limit`: Horizontal gaze boundaries (0.0-1.0)
- `down_limit`: Vertical downward gaze threshold
- `smoothing_factor`: Temporal smoothing intensity (0.0-1.0)

#### Object Detection
- `phone_confidence`: Minimum confidence for phone detection
- `watch_confidence`: Minimum confidence for smartwatch detection
- `nms_threshold`: Non-maximum suppression threshold

#### Recording Settings
- `save_path`: Directory for recorded videos
- `format`: Video output format (mp4, avi)
- `quality`: Recording quality (low, medium, high)

## ğŸ¯ Usage

### Basic Operation

1. **Start Monitoring**
   ```bash
   python gui_app.py
   ```

2. **Generate Test Images** (Optional)
   ```bash
   python generate_test_images.py
   ```

3. **Begin Examination**
   - Click "Start Monitoring" to begin surveillance
   - System will automatically detect and log violations
   - Red alerts appear for detected violations

### Batch Image Processing

For testing gaze detection on static images:

```bash
# Place test images in input_images/ directory
python image_gaze_analyzer.py
# Check results in analyzed_images/ directory and logs/
```

### Advanced Features

#### Custom Violation Rules
```python
# Add custom violation detection
system.violation_monitor.add_custom_rule(
    name="extended_downward_gaze",
    condition=lambda data: data['v_ratio'] > 0.7,
    duration_threshold=3.0
)
```

#### Testing and Analysis Tools
- **Generate Test Images**: PyQt5-based tool for capturing calibrated gaze images
- **Image Gaze Analyzer**: Batch processing tool with detailed logging and analysis
- **Configuration Testing**: Tools to validate and optimize detection thresholds

## ğŸ—ï¸ Architecture

### Core Components

```
anti-plagiat/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ gaze_tracking/
â”‚   â”‚   â”œâ”€â”€ gaze_tracker.py      # MediaPipe-based gaze tracking engine
â”‚   â”‚   â”œâ”€â”€ eye.py               # Eye region detection and analysis
â”‚   â”‚   â”œâ”€â”€ pupil.py             # Enhanced pupil detection
â”‚   â”‚   â””â”€â”€ pupil_tracker.py     # Temporal tracking and filtering
â”‚   â”œâ”€â”€ face_detector.py         # Face detection integration
â”‚   â”œâ”€â”€ object_detector.py       # YOLOv8-based object detection
â”‚   â”œâ”€â”€ violation_monitor.py     # Violation detection logic
â”‚   â”œâ”€â”€ video_handler.py         # Video processing and recording
â”‚   â””â”€â”€ report_generator.py      # Report generation
â”œâ”€â”€ gui_app.py                   # Main PyQt5 GUI application
â”œâ”€â”€ main.py                      # Core system logic
â”œâ”€â”€ generate_test_images.py      # PyQt5-based test image generator
â”œâ”€â”€ image_gaze_analyzer.py       # Batch image analysis tool
â””â”€â”€ config.json                  # Configuration file
```

### Algorithm Overview

#### Gaze Tracking Pipeline
1. **Face Detection**: MediaPipe Face Mesh detection with 468 landmarks
2. **Eye Region Isolation**: Extract left and right eye regions using specific landmarks
3. **Pupil Detection**: Multi-method pupil localization with geometric validation
4. **Gaze Calculation**: Compute horizontal and vertical ratios for direction determination
5. **Temporal Filtering**: Smoothing and noise reduction
6. **Violation Assessment**: Compare against configurable thresholds

#### Enhanced Object Detection
- **Dual YOLOv8 Models**: Separate specialized models for phones and smartwatches
- **Confidence Thresholding**: Different confidence levels for different object types
- **Dimension-based Classification**: Additional validation based on object dimensions
- **Temporal Consistency**: Multi-frame validation to reduce false positives

#### MediaPipe Integration
- **Face Mesh Detection**: 468 facial landmarks for precise eye tracking
- **Real-time Processing**: Optimized for live video streams
- **Robust Landmark Detection**: Works across various lighting conditions and poses
- **Silent Operation**: Suppressed output for clean user experience

## ğŸ”§ Troubleshooting

### Common Issues

#### Camera Not Detected
```bash
# Check available cameras
python -c "import cv2; print([i for i in range(10) if cv2.VideoCapture(i).isOpened()])"
# Update camera source in config.json
```

#### Poor Gaze Detection Accuracy
1. Ensure good lighting conditions
2. Adjust detection thresholds in config.json
3. Check camera positioning (eye-level recommended)
4. Test with generate_test_images.py for calibration

#### High CPU Usage
1. Reduce camera resolution in config.json
2. Increase frame processing interval
3. Disable recording if not needed
4. Close other resource-intensive applications

#### Qt Platform Plugin Errors
```bash
# If using conda environment
export QT_QPA_PLATFORM_PLUGIN_PATH=""
export OPENCV_IO_ENABLE_OPENEXR=0
```

### Debug Mode
```bash
# Check logs in logs/ directory after running image analysis
python image_gaze_analyzer.py
# Logs saved to logs/gaze_analysis_YYYYMMDD_HHMMSS.log
```

## ğŸ§ª Testing

### Test Image Generation
```bash
# Generate calibrated test images
python generate_test_images.py
# Images saved to input_images/ directory
```

### Batch Analysis
```bash
# Analyze generated test images
python image_gaze_analyzer.py
# Results in analyzed_images/ and logs/
```

### Performance Testing
```bash
# Test camera functionality
python test_camera.py
```

## ğŸ“Š Performance Metrics

### Typical Performance
- **Gaze Detection Accuracy**: 85-95% (with proper lighting and positioning)
- **Processing Speed**: 25-30 FPS (640x480 resolution)
- **False Positive Rate**: <5%
- **Object Detection Accuracy**: 88-94% (YOLOv8 models)

### Optimization Tips
- Use proper lighting setup
- Position camera at eye level
- Optimize camera resolution for use case
- Regular threshold adjustment based on environment
- Use headless OpenCV to avoid GUI conflicts

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

### Development Guidelines
- Follow PEP 8 style guide
- Add docstrings for all functions
- Include unit tests for new features
- Update documentation as needed
- Test with both PyQt5 GUI and batch processing tools

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **MediaPipe** library for facial landmark detection
- **OpenCV** for computer vision capabilities
- **PyQt5** for GUI framework
- **YOLOv8/Ultralytics** for object detection
- **NumPy** for numerical computations
- Research papers on gaze tracking and eye detection algorithms

## ğŸ“ Support

For support and questions:
- Create an issue on GitHub
- Check the troubleshooting section
- Review configuration documentation
- Check logs in logs/ directory for detailed analysis

## ğŸ”„ Version History

- **v3.0.0**: Complete redesign with MediaPipe, YOLOv8, and enhanced PyQt5 tools
- **v2.0.0**: Enhanced gaze tracking with Kalman filtering and user calibration
- **v1.5.0**: Added object detection and improved GUI
- **v1.0.0**: Initial release with basic gaze tracking

---

**Note**: This system is designed for educational and examination monitoring purposes. Ensure compliance with local privacy laws and institutional policies before deployment.